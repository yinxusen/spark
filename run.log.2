Using /Library/Java/JavaVirtualMachines/jdk1.8.0_31.jdk/Contents/Home as default JAVA_HOME.
Note, this will be overridden by -java-home if it is set.
[0m[[0minfo[0m] [0mLoading project definition from /Users/panda/git-store/spark/project/project[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/panda/.sbt/0.13/staging/ad8e8574a5bcb2d22d23/sbt-pom-reader/project[0m
[0m[[33mwarn[0m] [0mMultiple resolvers having different access mechanism configured with same name 'sbt-plugin-releases'. To avoid conflict, Remove duplicate project resolvers (`resolvers`) or rename publishing resolver (`publishTo`).[0m
[0m[[0minfo[0m] [0mLoading project definition from /Users/panda/git-store/spark/project[0m
[0m[[0minfo[0m] [0mSet current project to spark-parent (in build file:/Users/panda/git-store/spark/)[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:78: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    accumulator: Accumulator[JList[Array[Byte]]])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:78: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    accumulator: Accumulator[JList[Array[Byte]]])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:78: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    accumulator: Accumulator[JList[Array[Byte]]])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:71: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0mprivate[spark] case class PythonFunction([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:78: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    accumulator: Accumulator[JList[Array[Byte]]])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala:873: trait AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  extends AccumulatorParam[JList[Array[Byte]]] {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/util/AccumulatorV2.scala:448: trait AccumulableParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    param: org.apache.spark.AccumulableParam[R, T]) extends AccumulatorV2[T, R] {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/util/AccumulatorV2.scala:448: trait AccumulableParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    param: org.apache.spark.AccumulableParam[R, T]) extends AccumulatorV2[T, R] {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:533: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def intAccumulator(initialValue: Int): Accumulator[java.lang.Integer] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:534: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(IntAccumulatorParam).asInstanceOf[Accumulator[java.lang.Integer]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:534: object IntAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(IntAccumulatorParam).asInstanceOf[Accumulator[java.lang.Integer]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:534: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(IntAccumulatorParam).asInstanceOf[Accumulator[java.lang.Integer]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:534: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(IntAccumulatorParam).asInstanceOf[Accumulator[java.lang.Integer]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:542: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def intAccumulator(initialValue: Int, name: String): Accumulator[java.lang.Integer] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:543: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(IntAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:543: object IntAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(IntAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:543: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(IntAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:544: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      .asInstanceOf[Accumulator[java.lang.Integer]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:550: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def doubleAccumulator(initialValue: Double): Accumulator[java.lang.Double] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:551: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(DoubleAccumulatorParam).asInstanceOf[Accumulator[java.lang.Double]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:551: object DoubleAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(DoubleAccumulatorParam).asInstanceOf[Accumulator[java.lang.Double]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:551: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(DoubleAccumulatorParam).asInstanceOf[Accumulator[java.lang.Double]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:551: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(DoubleAccumulatorParam).asInstanceOf[Accumulator[java.lang.Double]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:559: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def doubleAccumulator(initialValue: Double, name: String): Accumulator[java.lang.Double] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:560: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(DoubleAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:560: object DoubleAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(DoubleAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:560: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(DoubleAccumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:561: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      .asInstanceOf[Accumulator[java.lang.Double]][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:567: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator(initialValue: Int): Accumulator[java.lang.Integer] = intAccumulator(initialValue)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:575: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator(initialValue: Int, name: String): Accumulator[java.lang.Integer] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:582: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator(initialValue: Double): Accumulator[java.lang.Double] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:592: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator(initialValue: Double, name: String): Accumulator[java.lang.Double] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:599: trait AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator[T](initialValue: T, accumulatorParam: AccumulatorParam[T]): Accumulator[T] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:599: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator[T](initialValue: T, accumulatorParam: AccumulatorParam[T]): Accumulator[T] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:600: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue)(accumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:608: trait AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulator[T](initialValue: T, name: String, accumulatorParam: AccumulatorParam[T])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:609: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      : Accumulator[T] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:610: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulator(initialValue, name)(accumulatorParam)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:616: trait AccumulableParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulable[T, R](initialValue: T, param: AccumulableParam[T, R]): Accumulable[T, R] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:616: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulable[T, R](initialValue: T, param: AccumulableParam[T, R]): Accumulable[T, R] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:617: method accumulable in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulable(initialValue)(param)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:625: trait AccumulableParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def accumulable[T, R](initialValue: T, name: String, param: AccumulableParam[T, R])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:626: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      : Accumulable[T, R] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:627: method accumulable in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    sc.accumulable(initialValue, name)(param)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0mMultiple main classes detected.  Run 'show discoveredMainClasses' to see the list[0m
[0m[[33mwarn[0m] [0mMultiple main classes detected.  Run 'show discoveredMainClasses' to see the list[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:386: method tpe in trait AnnotationApi is deprecated: Use `tree.tpe` instead[0m
[0m[[33mwarn[0m] [0m      case t if t.typeSymbol.annotations.exists(_.tpe =:= typeOf[SQLUserDefinedType]) =>[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:610: method tpe in trait AnnotationApi is deprecated: Use `tree.tpe` instead[0m
[0m[[33mwarn[0m] [0m        case t if t.typeSymbol.annotations.exists(_.tpe =:= typeOf[SQLUserDefinedType]) =>[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:702: method tpe in trait AnnotationApi is deprecated: Use `tree.tpe` instead[0m
[0m[[33mwarn[0m] [0m      case t if t.typeSymbol.annotations.exists(_.tpe =:= typeOf[SQLUserDefinedType]) =>[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:798: method normalize in class TypeApi is deprecated: Use `dealias` or `etaExpand` instead[0m
[0m[[33mwarn[0m] [0m    tag.in(mirror).tpe.normalize[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:839: value nme in trait StandardNames is deprecated: Use `termNames` instead[0m
[0m[[33mwarn[0m] [0m    val constructorSymbol = tpe.member(nme.CONSTRUCTOR)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:841: method paramss in trait MethodSymbolApi is deprecated: Use `paramLists` instead[0m
[0m[[33mwarn[0m] [0m      constructorSymbol.asMethod.paramss[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala:849: method paramss in trait MethodSymbolApi is deprecated: Use `paramLists` instead[0m
[0m[[33mwarn[0m] [0m        primaryConstructorSymbol.get.asMethod.paramss[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/codegen/package.scala:54: class AbstractFileClassLoader in package interpreter is deprecated: Use `scala.tools.nsc.util.AbstractFileClassLoader`[0m
[0m[[33mwarn[0m] [0m          .asInstanceOf[scala.tools.nsc.interpreter.AbstractFileClassLoader][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:110: trait AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    implicit object SetAccumulatorParam extends AccumulatorParam[HashSet[String]] {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:128: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    case class ColumnMetrics([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:129: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      elementTypes: Accumulator[HashSet[String]] = sparkContext.accumulator(HashSet.empty))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:131: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    val tupleCount: Accumulator[Int] = sparkContext.accumulator[Int](0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:131: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    val tupleCount: Accumulator[Int] = sparkContext.accumulator[Int](0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:131: object IntAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    val tupleCount: Accumulator[Int] = sparkContext.accumulator[Int](0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala:131: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    val tupleCount: Accumulator[Int] = sparkContext.accumulator[Int](0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:75: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  private[sql] val batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] =[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:77: method accumulableCollection in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      child.sqlContext.sparkContext.accumulableCollection(ArrayBuffer.empty[InternalRow])[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:70: class Accumulable in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m    private[sql] var _batchStats: Accumulable[ArrayBuffer[InternalRow], InternalRow] = null)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:292: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readPartitions: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:292: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readPartitions: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:292: object IntAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readPartitions: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:292: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readPartitions: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:293: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readBatches: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:293: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readBatches: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:293: object IntAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readBatches: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/InMemoryTableScanExec.scala:293: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  lazy val readBatches: Accumulator[Int] = sparkContext.accumulator(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:282: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      val costAccums = activeRuns.map(_ => sc.accumulator(0.0))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:282: object DoubleAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      val costAccums = activeRuns.map(_ => sc.accumulator(0.0))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala:282: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m      val costAccums = activeRuns.map(_ => sc.accumulator(0.0))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.scala:48: class LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m  extends StreamingLinearAlgorithm[LinearRegressionModel, LinearRegressionWithSGD][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.scala:61: class LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m  val algorithm = new LinearRegressionWithSGD(stepSize, numIterations, regParam, miniBatchFraction)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:570: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    !model.getFitIntercept)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:634: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m  private val degreesOfFreedom: Long = if (model.getFitIntercept) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:635: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    numInstances - model.coefficients.size - 1[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:637: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    numInstances - model.coefficients.size[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:645: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    val weighted = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:645: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    val weighted = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:645: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    val weighted = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:648: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m      sqrt(col(model.getWeightCol))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:650: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    val dr = predictions.select(col(model.getLabelCol).minus(col(model.getPredictionCol))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:650: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m    val dr = predictions.select(col(model.getLabelCol).minus(col(model.getPredictionCol))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:671: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m      val rss = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:671: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m      val rss = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:671: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m      val rss = if (!model.isDefined(model.weightCol) || model.getWeightCol.isEmpty) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:676: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m        predictions.select(t(col(model.getPredictionCol), col(model.getLabelCol),[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:676: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m        predictions.select(t(col(model.getPredictionCol), col(model.getLabelCol),[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:677: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m          col(model.getWeightCol)).as("wse")).agg(sum(col("wse"))).first().getDouble(0)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:698: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m      val estimate = if (model.getFitIntercept) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:699: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m        Array.concat(model.coefficients.toArray, Array(model.intercept))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:699: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m        Array.concat(model.coefficients.toArray, Array(model.intercept))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala:701: value model in class LinearRegressionSummary is deprecated: The model field is deprecated and will be removed in 2.1.0.[0m
[0m[[33mwarn[0m] [0m        model.coefficients.toArray[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/util/stopwatches.scala:105: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  private val elapsedTime: Accumulator[Long] = sc.accumulator(0L, s"DistributedStopwatch($name)")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/util/stopwatches.scala:105: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  private val elapsedTime: Accumulator[Long] = sc.accumulator(0L, s"DistributedStopwatch($name)")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/util/stopwatches.scala:105: object LongAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  private val elapsedTime: Accumulator[Long] = sc.accumulator(0L, s"DistributedStopwatch($name)")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/util/stopwatches.scala:105: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  private val elapsedTime: Accumulator[Long] = sc.accumulator(0L, s"DistributedStopwatch($name)")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/evaluation/MulticlassClassificationEvaluator.scala:85: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m      case "precision" => metrics.precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/ml/evaluation/MulticlassClassificationEvaluator.scala:86: value recall in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m      case "recall" => metrics.recall[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:153: class LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val lrAlg = new LinearRegressionWithSGD()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:182: class LassoWithSGD in package regression is deprecated: Use ml.regression.LinearRegression with elasticNetParam = 1.0. Note the default regParam is 0.01 for LassoWithSGD, but is 0.0 for LinearRegression.[0m
[0m[[33mwarn[0m] [0m    val lassoAlg = new LassoWithSGD()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:210: class RidgeRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression with elasticNetParam = 0.0. Note the default regParam is 0.01 for RidgeRegressionWithSGD, but is 0.0 for LinearRegression.[0m
[0m[[33mwarn[0m] [0m    val ridgeAlg = new RidgeRegressionWithSGD()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/api/python/PythonMLLibAPI.scala:269: class LogisticRegressionWithSGD in package classification is deprecated: Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS[0m
[0m[[33mwarn[0m] [0m    val LogRegAlg = new LogisticRegressionWithSGD()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.scala:51: class LogisticRegressionWithSGD in package classification is deprecated: Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS[0m
[0m[[33mwarn[0m] [0m  extends StreamingLinearAlgorithm[LogisticRegressionModel, LogisticRegressionWithSGD][0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/mllib/src/main/scala/org/apache/spark/mllib/classification/StreamingLogisticRegressionWithSGD.scala:63: class LogisticRegressionWithSGD in package classification is deprecated: Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS[0m
[0m[[33mwarn[0m] [0m  protected val algorithm = new LogisticRegressionWithSGD([0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0mMultiple main classes detected.  Run 'show discoveredMainClasses' to see the list[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala:41: method declarations in class TypeApi is deprecated: Use `decls` instead[0m
[0m[[33mwarn[0m] [0m    val allAccessors = tpe.declarations.collect {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala:57: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  @volatile private var instance: Accumulator[Long] = null[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala:59: class Accumulator in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m  def getInstance(sc: SparkContext): Accumulator[Long] = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala:63: method accumulator in class SparkContext is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m          instance = sc.accumulator(0L, "WordsInBlacklistCounter")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala:63: object LongAccumulatorParam in object AccumulatorParam is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m          instance = sc.accumulator(0L, "WordsInBlacklistCounter")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala:63: object AccumulatorParam in package spark is deprecated: use AccumulatorV2[0m
[0m[[33mwarn[0m] [0m          instance = sc.accumulator(0L, "WordsInBlacklistCounter")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala:299: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m            .precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala:302: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m          new MulticlassMetrics(test.map(lp => (model.predict(lp.features), lp.label))).precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala:326: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m            .precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala:329: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m          new MulticlassMetrics(test.map(lp => (model.predict(lp.features), lp.label))).precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala:115: class LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val algorithm = new LinearRegressionWithSGD()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala:51: object LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val model = LinearRegressionWithSGD.train(training, numIterations)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala:52: object LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val model_pca = LinearRegressionWithSGD.train(training_pca, numIterations)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala:46: object LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val model = LinearRegressionWithSGD.train(parsedData, numIterations, stepSize)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala:43: object LinearRegressionWithSGD in package regression is deprecated: Use ml.regression.LinearRegression or LBFGS[0m
[0m[[33mwarn[0m] [0m    val model = LinearRegressionWithSGD.train(data, numIterations)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala:324: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m    val accuracy = new MulticlassMetrics(predictions.zip(labels)).precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala:57: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m    val precision = metrics.precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala:62: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m    val precision = metrics.precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala:63: value recall in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m    val recall = metrics.recall // same as true positive rate[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala:64: value fMeasure in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m    val f1Score = metrics.fMeasure[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/sql/hive/HiveFromSpark.scala:75: method registerTempTable in class Dataset is deprecated: Use createOrReplaceTempView(viewName) instead.[0m
[0m[[33mwarn[0m] [0m    rdd.toDF().registerTempTable("records")[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala:124: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m          .precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/Users/panda/git-store/spark/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala:127: value precision in class MulticlassMetrics is deprecated: Use accuracy.[0m
[0m[[33mwarn[0m] [0m        new MulticlassMetrics(test.map(lp => (model.predict(lp.features), lp.label))).precision[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0mMultiple main classes detected.  Run 'show discoveredMainClasses' to see the list[0m
[0m[[0minfo[0m] [0mRunning org.apache.spark.examples.ml.AirlineDataToNumeric /Users/panda[0m
xusen, Partitions of train set is 10
+--------------------+-----+
|            features|label|
+--------------------+-----+
|[0.0,20.0,5.0,1.0...|  0.0|
|[5.0,2.0,3.0,6.0,...|  0.0|
|[10.0,13.0,1.0,8....|  0.0|
|[9.0,4.0,6.0,2.0,...|  0.0|
|[4.0,8.0,6.0,0.0,...|  1.0|
|[0.0,27.0,2.0,7.0...|  0.0|
|[8.0,14.0,2.0,3.0...|  0.0|
|[5.0,29.0,6.0,11....|  0.0|
|[1.0,15.0,1.0,1.0...|  0.0|
|[6.0,2.0,4.0,2.0,...|  0.0|
|[3.0,20.0,6.0,3.0...|  0.0|
|[2.0,3.0,5.0,0.0,...|  0.0|
|[4.0,5.0,2.0,15.0...|  0.0|
|[0.0,2.0,6.0,1.0,...|  0.0|
|[9.0,12.0,2.0,5.0...|  0.0|
|[10.0,2.0,4.0,4.0...|  0.0|
|[10.0,0.0,4.0,9.0...|  0.0|
|[1.0,9.0,4.0,3.0,...|  0.0|
|[4.0,1.0,1.0,2.0,...|  1.0|
|[4.0,3.0,2.0,6.0,...|  0.0|
+--------------------+-----+
only showing top 20 rows

[0m[[31merror[0m] [0m(run-main-0) java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.[0m
[0m[[31merror[0m] [0mThis stopped SparkContext was created at:[0m
[0m[[31merror[0m] [0m[0m
[0m[[31merror[0m] [0morg.apache.spark.SparkContext.<init>(SparkContext.scala:82)[0m
[0m[[31merror[0m] [0morg.apache.spark.examples.ml.AirlineDataToNumeric$.main(AirlineDataToNumeric.scala:39)[0m
[0m[[31merror[0m] [0morg.apache.spark.examples.ml.AirlineDataToNumeric.main(AirlineDataToNumeric.scala)[0m
[0m[[31merror[0m] [0msun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[31merror[0m] [0msun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[31merror[0m] [0msun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[31merror[0m] [0mjava.lang.reflect.Method.invoke(Method.java:483)[0m
[0m[[31merror[0m] [0msbt.Run.invokeMain(Run.scala:67)[0m
[0m[[31merror[0m] [0msbt.Run.run0(Run.scala:61)[0m
[0m[[31merror[0m] [0msbt.Run.sbt$Run$$execute$1(Run.scala:51)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Logger$$anon$4.apply(Logger.scala:84)[0m
[0m[[31merror[0m] [0msbt.TrapExit$App.run(TrapExit.scala:248)[0m
[0m[[31merror[0m] [0mjava.lang.Thread.run(Thread.java:745)[0m
[0m[[31merror[0m] [0m[0m
[0m[[31merror[0m] [0mThe currently active SparkContext was created at:[0m
[0m[[31merror[0m] [0m[0m
[0m[[31merror[0m] [0morg.apache.spark.SparkContext.<init>(SparkContext.scala:82)[0m
[0m[[31merror[0m] [0morg.apache.spark.examples.ml.AirlineDataToNumeric$.main(AirlineDataToNumeric.scala:39)[0m
[0m[[31merror[0m] [0morg.apache.spark.examples.ml.AirlineDataToNumeric.main(AirlineDataToNumeric.scala)[0m
[0m[[31merror[0m] [0msun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[31merror[0m] [0msun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[31merror[0m] [0msun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[31merror[0m] [0mjava.lang.reflect.Method.invoke(Method.java:483)[0m
[0m[[31merror[0m] [0msbt.Run.invokeMain(Run.scala:67)[0m
[0m[[31merror[0m] [0msbt.Run.run0(Run.scala:61)[0m
[0m[[31merror[0m] [0msbt.Run.sbt$Run$$execute$1(Run.scala:51)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Run$$anonfun$run$1.apply(Run.scala:55)[0m
[0m[[31merror[0m] [0msbt.Logger$$anon$4.apply(Logger.scala:84)[0m
[0m[[31merror[0m] [0msbt.TrapExit$App.run(TrapExit.scala:248)[0m
[0m[[31merror[0m] [0mjava.lang.Thread.run(Thread.java:745)[0m
[0m[[31merror[0m] [0m         [0m
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.<init>(SparkContext.scala:82)
org.apache.spark.examples.ml.AirlineDataToNumeric$.main(AirlineDataToNumeric.scala:39)
org.apache.spark.examples.ml.AirlineDataToNumeric.main(AirlineDataToNumeric.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:483)
sbt.Run.invokeMain(Run.scala:67)
sbt.Run.run0(Run.scala:61)
sbt.Run.sbt$Run$$execute$1(Run.scala:51)
sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
sbt.Run$$anonfun$run$1.apply(Run.scala:55)
sbt.Run$$anonfun$run$1.apply(Run.scala:55)
sbt.Logger$$anon$4.apply(Logger.scala:84)
sbt.TrapExit$App.run(TrapExit.scala:248)
java.lang.Thread.run(Thread.java:745)

The currently active SparkContext was created at:

org.apache.spark.SparkContext.<init>(SparkContext.scala:82)
org.apache.spark.examples.ml.AirlineDataToNumeric$.main(AirlineDataToNumeric.scala:39)
org.apache.spark.examples.ml.AirlineDataToNumeric.main(AirlineDataToNumeric.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:483)
sbt.Run.invokeMain(Run.scala:67)
sbt.Run.run0(Run.scala:61)
sbt.Run.sbt$Run$$execute$1(Run.scala:51)
sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
sbt.Run$$anonfun$run$1.apply(Run.scala:55)
sbt.Run$$anonfun$run$1.apply(Run.scala:55)
sbt.Logger$$anon$4.apply(Logger.scala:84)
sbt.TrapExit$App.run(TrapExit.scala:248)
java.lang.Thread.run(Thread.java:745)
         
	at org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:106)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1369)
	at org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:500)
	at org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:187)
	at org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:114)
	at org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:47)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:90)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:71)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.Estimator$$anonfun$fit$1.apply(Estimator.scala:82)
	at org.apache.spark.ml.Estimator$$anonfun$fit$1.apply(Estimator.scala:82)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:82)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:108)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:103)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:103)
	at org.apache.spark.examples.ml.AirlineDataToNumeric$.main(AirlineDataToNumeric.scala:108)
	at org.apache.spark.examples.ml.AirlineDataToNumeric.main(AirlineDataToNumeric.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
[0m[[31mtrace[0m] [0mStack trace suppressed: run [34mlast examples/compile:runMain[0m for the full output.[0m
